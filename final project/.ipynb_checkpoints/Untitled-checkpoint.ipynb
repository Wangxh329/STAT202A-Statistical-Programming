{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    " Stat 202A 2018 Fall - Final Project\n",
    " Author: Xiaohan Wang\n",
    " Date : 12/15/2018\n",
    "\n",
    " Description: This is the final project for STAT 202A 2018 Fall. \n",
    " Two functions are required, spectual clustering and t-SNE.\n",
    "\n",
    " INSTRUCTIONS: Please fill in the missing lines of code\n",
    " only where specified. You can modify any line in the function except the\n",
    " function names, function inputs or outputs. \n",
    " You can add examples in \"if __name__ == '__main__':\"\n",
    " (in the \"Optional examples\" section). However, DO NOT LEAVE \n",
    " CODE OUTSIDE ANY FUNCTION.\n",
    " \n",
    " I will import your code, if it is outside of any function, \n",
    " it will run during import and led to error making you got \n",
    " CE(Compile error) which is zero score. You can do partial score\n",
    " HOWEVER, make sure it is runable. (e.g. even you do not run t-SNE, \n",
    " if you do not comment out all t-SNE function, you may get CE in spectral\n",
    " Clustering because I cannot import your python files.)\n",
    "\n",
    " Do not use any of Python's built in functions for matrix \n",
    " inversion or for linear modeling (except for debugging or \n",
    " in the optional examples section).\n",
    "\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "########################################################\n",
    "#           Function 1 : Spectral Clustering\n",
    "########################################################\n",
    "\n",
    "def s(x, y, sigma=1.0):\n",
    "    return np.exp(-1/(2 * sigma**2) * np.sum((x - y)**2))\n",
    "\n",
    "def create_S(X, s, eps=1.0e-50):\n",
    "\n",
    "    ################################\n",
    "    # TODO (1) implement\n",
    "    # (1) note, s(x,y) is a function\n",
    "    # (2) note, set S[i,j] = 0 if s(x,y) < eps\n",
    "    ################################\n",
    "\n",
    "    n = X.shape[0]\n",
    "    S = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                S[i, j] = 0\n",
    "                continue\n",
    "            S_ij = s(X[i], X[j])\n",
    "            if S_ij < eps:\n",
    "                S_ij = 0\n",
    "            S[i, j] = S_ij\n",
    "    \n",
    "    return S\n",
    "\n",
    "\n",
    "def create_L(X, s):\n",
    "\n",
    "    ################################\n",
    "    # TODO (2) implement\n",
    "    ################################\n",
    "\n",
    "    n = X.shape[0]\n",
    "    S = create_S(X, s)\n",
    "    D = np.zeros((n, n))\n",
    "    \n",
    "    for j in range(n):\n",
    "        D[j, j] = 1 / np.sqrt(np.sum(S[:, j]))\n",
    "    \n",
    "    L = np.dot(D, np.dot(S, D))\n",
    "    return L\n",
    "\n",
    "\n",
    "def create_Y(X, s, num_eigs=2):\n",
    "\n",
    "    ################################\n",
    "    # TODO (3) implement\n",
    "    # * Please use your own eigen_decomposition \n",
    "    ################################\n",
    "    \n",
    "    eigen_value, eigen_vector = np.linalg.eig(create_L(X, s))\n",
    "    eigen_vector = eigen_vector[:, eigen_value.argsort()[::-1]]\n",
    "    Y = eigen_vector[:, :num_eigs]\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "def k_means(X, k=2, tol=1e-6, max_iter=300, break_limit=5, num_restarts=10):\n",
    "\n",
    "    ################################\n",
    "    # TODO Write comments for k_means.\n",
    "    #  Already implemented, do not need to modify the code.\n",
    "    ################################\n",
    "    n, p = X.shape\n",
    "    performances = np.zeros(num_restarts)  # store performances in num_restarts k-means\n",
    "    cluster_array = np.zeros((n, num_restarts)) # store cluster result in num_restarts k-means\n",
    "\n",
    "    for t in range(num_restarts):  # for each k-means process\n",
    "\n",
    "        centroids = np.zeros((k, p))  # randomly select k start centroids\n",
    "        shuffle_X = shuffle(X)\n",
    "        for i in range(k):\n",
    "            centroids[i] = shuffle_X[i]\n",
    "\n",
    "        distances = np.zeros(max_iter)\n",
    "        break_count = 1\n",
    "\n",
    "        for iter in range(max_iter):  # there are at most max_iter rounds in each k-means process\n",
    "            cluster_membership = np.zeros(n)  # cluster each X_i to specific group according to the distance\n",
    "            for i in range(n):  # for each X_i\n",
    "                dist_vec = np.zeros(k)\n",
    "                for j in range(k):  # for each group\n",
    "                    dist_vec[j] = np.sum((X[i, :] - centroids[j, :])**2)\n",
    "                cluster_membership[i] = np.argmin(dist_vec)  # select the closest centroid\n",
    "            cluster_membership = cluster_membership.astype(int)\n",
    "\n",
    "            for i in range(k): # update position of each centroid (the mean position of each group)\n",
    "                centroids[i] = np.mean(X[cluster_membership == i, :], axis=0)\n",
    "\n",
    "            ind_dist = np.zeros(n)  # calculate sum of distance as performance\n",
    "            for i in range(n):  # for each X_i, calculate the distance to its centroid\n",
    "                ind_dist[i] = np.sum(\n",
    "                    (X[i, :] - centroids[cluster_membership[i], :])**2)\n",
    "            distances[iter] = np.sum(ind_dist**2)\n",
    "\n",
    "            distance_difference = np.sum(\n",
    "                (distances[iter] - distances[iter - 1])**2)\n",
    "            break_count = break_count + 1 if distance_difference < tol else 1  # if dis < tol, break_count plus 1\n",
    "\n",
    "            if break_count >= break_limit:  # if there are break_limit continuous iterations \n",
    "                break                       # with satisfied sum of distances, then break current k-means process\n",
    "\n",
    "        cluster_array[:, t] = cluster_membership\n",
    "        performances[t] = distances[iter]\n",
    "\n",
    "    best_iteration = np.argmin(performances)  # select final cluster result with best performance (min sum of distances)\n",
    "    final_clusters = cluster_array[:, best_iteration]\n",
    "\n",
    "    return final_clusters\n",
    "\n",
    "def spectral_clustering(X, s, num_eigs=2, k=2):\n",
    "\n",
    "    Y = create_Y(X, s, num_eigs)\n",
    "    labels = k_means(Y, k)\n",
    "    return Y, labels\n",
    "\n",
    "def test_problem1():\n",
    "    np.random.seed(1)\n",
    "\n",
    "    def xy(eta, n):\n",
    "\n",
    "        theta = np.random.uniform(0, 2 * np.pi, n)\n",
    "        x = eta * np.cos(theta) + np.random.normal(0, 0.05, n)\n",
    "        y = eta * np.sin(theta) + np.random.normal(0, 0.05, n)\n",
    "        return x, y\n",
    "\n",
    "    sigmas = [0.1, 0.2, 0.5, 1.0]\n",
    "    num_eigs_list = [2**1, 2**2, 2**3, 2**4]\n",
    "\n",
    "    x0, y0 = xy(0.1, 50)\n",
    "    x1, y1 = xy(1.0, 200)\n",
    "    x2, y2 = xy(2.0, 400)\n",
    "\n",
    "    x = np.concatenate((x0, x1, x2), axis=0)\n",
    "    y = np.concatenate((y0, y1, y2), axis=0)\n",
    "    X = np.transpose(np.vstack((x, y)))\n",
    "\n",
    "    def create_s(sigma): return lambda x, y: s(x, y, sigma=sigma)\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.matshow(create_S(X, create_s(sigma)), cmap=plt.cm.Reds)\n",
    "        plt.title('S sigma = {}'.format(sigma))\n",
    "    for sigma in sigmas:\n",
    "        E1, Z1 = np.linalg.eig(create_L(X, create_s(sigma)))\n",
    "        Z1 = Z1[:, E1.argsort()[::-1]]\n",
    "        plt.clf()\n",
    "        plt.plot(Z1[:, 1])\n",
    "        plt.title('Eigenvector 1 sigma = {}'.format(sigma))\n",
    "        plt.savefig(\"Final_P1_Eigenvector1_%d.png\" % (sigma*10))\n",
    "        plt.clf()\n",
    "        plt.plot(Z1[:, 2])\n",
    "        plt.title('Eigenvector 2 sigma = {}'.format(sigma))\n",
    "        plt.savefig(\"Final_P1_Eigenvector2_%d.png\" % (sigma*10))\n",
    "        plt.clf()\n",
    "\n",
    "    plt.scatter(x0, y0, c='r', marker='x')\n",
    "    plt.scatter(x1, y1, c='b', marker='o')\n",
    "    plt.scatter(x2, y2, c='g', marker='o')\n",
    "    plt.title('True classes')\n",
    "    plt.savefig(\"Final_P1_True_Class.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    # Plot spectral_clustering results\n",
    "    for num_eigs in num_eigs_list:\n",
    "        for sigma in sigmas:\n",
    "            Y, class_pred = spectral_clustering(X, create_s(sigma), k=3, num_eigs=num_eigs)\n",
    "            plt.scatter(x[class_pred == 0], y[class_pred == 0], c='r', marker='x')\n",
    "            plt.scatter(x[class_pred == 1], y[class_pred == 1], c='b', marker='o')\n",
    "            plt.scatter(x[class_pred == 2], y[class_pred == 2], c='g', marker='o')\n",
    "            plt.title('Spectral clustering results sigma = {}, num(eigs) = {}'.format(sigma, num_eigs))\n",
    "            plt.savefig(\"Final_P1_matrix_%d_%d.png\" % (num_eigs, sigma*10))\n",
    "            plt.clf()\n",
    "\n",
    "    # Plot kmeans results \n",
    "    kmeans_pred = k_means(X, k=3)\n",
    "    plt.scatter(x[kmeans_pred == 0], y[kmeans_pred == 0], c='r', marker='x')\n",
    "    plt.scatter(x[kmeans_pred == 1], y[kmeans_pred == 1], c='b', marker='o')\n",
    "    plt.scatter(x[kmeans_pred == 2], y[kmeans_pred == 2], c='g', marker='o')\n",
    "    plt.title('K-means clustering results')\n",
    "    plt.savefig(\"Final_P1_kmean_result.png\")\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "#           Function 2 : t-SNE\n",
    "########################################################\n",
    "\n",
    "\n",
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "\n",
    "    # Calculate P vector and perplexity score.\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "\n",
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "\n",
    "    # Compute the conditional probability P(j|i)\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    for i in range(n):\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i + 1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i + 1:n]))] = thisP\n",
    "\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P\n",
    "\n",
    "\n",
    "def pca(X=np.array([]), no_dims=50):\n",
    "\n",
    "    # Apply PCA on X.\n",
    "    n = X.shape[0]\n",
    "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "    value, vector = np.linalg.eig(np.dot(X.T, X))\n",
    "    Y = np.dot(X, vector[:, 0:no_dims])\n",
    "    \n",
    "    return Y\n",
    "\n",
    "\n",
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "\n",
    "    # This is the main t-SNE method function. It does the algorithm by,\n",
    "    # 1. Run PCA by pca() and choose the real part.\n",
    "    # 2. Initialize the parameter and compute the conditional probability.\n",
    "    # 3. Start iteration to compute h\n",
    "\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # 1. Run PCA by pca().\n",
    "    X = pca(X, initial_dims)\n",
    "\n",
    "    # 2. Initialize the parameter and compute the conditional probability.\n",
    "    # Codes are for referance only.\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 1000\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Computes conditional probability p(j|i) based on equation (1) in paper\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # 3. Start iteration to compute h\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # 3.1 Calculate Q based on current h ($h_0$ is random vectors).\n",
    "        # Compute pairwise affinities\n",
    "        sum_y = np.sum(np.square(Y), 1)\n",
    "        num = 1 / (1 + np.add(np.add(-2 * np.dot(Y, Y.T), sum_y).T, sum_y))\n",
    "        num[range(n), range(n)] = 0\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i,:] = np.sum(np.tile(PQ[:,i] * num[:,i], (no_dims, 1)).T * (Y[i,:] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0) != (iY > 0)) + (gains * 0.8) * ((dY > 0) == (iY > 0))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # 3.2 Use gradient descent with momentum to minimize the KL divergence.\n",
    "\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4\n",
    "            \n",
    "    return Y\n",
    "\n",
    "def test_problem2():\n",
    "\n",
    "    print(\"Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\")\n",
    "    print(\"Running example on 2,500 MNIST digits...\")\n",
    "    X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    labels = np.loadtxt(\"mnist2500_labels.txt\")\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    colormap=['deepskyblue', 'coral', 'limegreen', 'gold', 'c', 'deeppink', 'mediumorchid', 'lightpink', 'olive', 'red']\n",
    "    plt.scatter(Y[:, 0], Y[:, 1], c=[colormap[i] for i in labels.astype(int)])\n",
    "    plt.savefig(\"Final_P2_scatter.png\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    test_problem1()\n",
    "    test_problem2()\n",
    "\n",
    "    # Optional examples\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
